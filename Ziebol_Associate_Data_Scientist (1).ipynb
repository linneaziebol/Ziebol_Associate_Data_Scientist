{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMA_recommendation_simulation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length: \",len(df))\n",
    "size = df.size\n",
    "shape = df.shape\n",
    "print(\"Size of DataSet: \", size)\n",
    "print(\"Shape of DataSet: \", shape)\n",
    "print(\"List of Data types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of this dataset is (161563, 16), and there are 7 unique Condition categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Condition Categories: \", df['CurrentCondition'].value_counts().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missingness: \\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns have missing data: order_distance, order_origin_weight, rate_norm, est_cost_norm, and CurrentCondtion. The request ID is unique because it is a type object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().unstack().sort_values(ascending = False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.order_distance, df.miles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatterplot of order distance plotted against miles, shows an obvious positive relationship. There is a steady incline, showing that as the order distance increases, the miles increase at about the same rate. This would make sense seeing that there is a very large correlation value of 0.982291."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.miles, df.est_cost_norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatterplot of miles plotted against estimated cost (normalized), shows a steep positive relationship. There is a large incline, showing that as the miles increase, normalized estimated cost increases at a very rapid rate. The correlation value of 0.742555 shows that these variables overlap much more than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.CurrentCondition.value_counts(normalize = True))\n",
    "df.CurrentCondition.value_counts().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar graph visualization shows how many orders are in each category of Current Condition. From the bars, we can see that most orders are Accepted, with Rejected being the second most likely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.pivot_table(data=df, index='CurrentCondition', columns='color',values='est_cost_norm')\n",
    "print(result)\n",
    "sn.heatmap(result, annot=True, cmap = 'RdYlGn', center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization gives a table as well as a heat map to explain what is going on. The boxes with darker red show that there is a lower estimated cost, while those with the green are at a higher estimated cost. The boxes themselves are fit to be in a category of the Current Condition and a category of the color given as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('request_id', axis=1)\n",
    "df = df.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['CurrentCondition'].notna()]\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "categ = ['order_equipment_type', 'weekday', 'CurrentCondition', 'color']\n",
    "df[categ] = df[categ].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the data with imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_origin_weight'].fillna(df['order_origin_weight'].mean(), inplace = True)\n",
    "df['rate_norm'].fillna(df['rate_norm'].mean(), inplace = True)\n",
    "df['est_cost_norm'].fillna(df['est_cost_norm'].mean(), inplace = True)\n",
    "df['order_distance'].fillna(df['order_distance'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree \n",
    "variables = df.iloc[:,:-1]\n",
    "results = df.iloc[:,-1]\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "tree_predictions = decision_tree.predict(X_test)\n",
    "tree_expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = (tree_predictions == tree_expected)\n",
    "print(\"Correct Matches:\", matches.sum())\n",
    "print(\"Data Points:\", len(matches))\n",
    "print(\"Accuracy Rate:\", matches.sum() / float(len(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(tree_predictions,tree_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(tree_predictions,tree_expected))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "imps = permutation_importance(decision_tree, X_test, y_test)\n",
    "tree_values= imps.importances_mean\n",
    "print(tree_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(df)\n",
    "del names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'names': names, 'values': tree_values}\n",
    "Table_tree = pd.DataFrame(data=data)\n",
    "print(Table_tree.sort_values(by='values', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Table_tree.plot.barh(x='names', y='values')\n",
    "ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(decision_tree, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification model is better to produce the Current Condition of a load. The model would place the load correctly  70.73% of the time. This is a decent way to predict a load. The geographic region and weight of the shipment are the best features of this model. The graph above explains the features with the most importance as having the highest bar graph. This model is slightly overfit, seeing that there are different mean scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "gnb_expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = (gnb_predictions == gnb_expected)\n",
    "print(\"Correct Matches:\", matches.sum())\n",
    "print(\"Data Points:\", len(matches))\n",
    "print(\"Accuracy Rate:\", matches.sum() / float(len(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(gnb_predictions,gnb_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(gnb_predictions,gnb_expected))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(gnb_predictions,gnb_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "imps = permutation_importance(gnb, X_test, y_test)\n",
    "values_gnb = list(imps.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'names': names, 'values': values_gnb}\n",
    "Table_gnb = pd.DataFrame(data=data)\n",
    "print(Table_gnb.sort_values(by='values', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Table_gnb.plot.barh(x='names', y='values')\n",
    "ax.set_ylabel(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(gnb, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification model is correct 53.73% of the time about the condition of a load. I would not recommend this model to predict the status of a load, seeing that it just barely over 50%. The most important features of this model are the shipment weight and the number of days before pickup date that the customer placed the order. Because of the error rate, we cannot confirm if these would even be the best features to use. This model is very overfit becasue of the large difference in mean scores. This model overall needs to be refit to be of more use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context and Critical Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have a few questions about this dataset that would have helped me to understand this analysis further. Who assigns the color of the order, is it automatic or manual (up for interpretation)? Does the type of truck requested rely on the weight of the load?\n",
    "\n",
    "In order to answer these questions, I would look to ask the team that assigns the color, possibly the vendor? I would aslo seek out who chooses the trucks for each load and determine if there is a cut off weight to choose equipment types. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
